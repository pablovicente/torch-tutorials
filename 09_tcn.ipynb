{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bb81da-ad98-418a-8405-5d8256d6029e",
   "metadata": {},
   "source": [
    "###Â Temporal Convolutional Network (TCN) for time series forecasting\n",
    "\n",
    "TCN model original code:\n",
    "- https://github.com/locuslab/TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76dbfd3-0854-4d4d-b212-a0846e7eefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59668624-4ff9-4a2e-a97b-a0192bad5455",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f72db1-3f48-4c5a-a666-8402139877ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21fd6f-38ce-46fc-aeaa-7b03a76e6d2a",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f28ec-3910-4f06-bc47-b2ef224e59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AileenNielsen/\"\n",
    "    \"TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "print(f\"# of samples: {len(df)}\")\n",
    "\n",
    "df[\"%Chg Passengers\"] = df[\"#Passengers\"].pct_change(1)\n",
    "\n",
    "# For simplicity, fill nans with 0\n",
    "# Note that the right strategy should be determined based\n",
    "# on project, target and dataset\n",
    "df[\"%Chg Passengers\"] = df[\"%Chg Passengers\"].fillna(0)\n",
    "\n",
    "# Visualize passenger data\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 4))\n",
    "_ = df[[\"#Passengers\"]].plot(ax=ax[0])\n",
    "_ = df[[\"%Chg Passengers\"]].plot(ax=ax[1])\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be3bc0-b011-4011-beec-e79478714d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate time series to forecast\n",
    "y = df[\"%Chg Passengers\"].values\n",
    "\n",
    "# Cast to float32 (default pytorch float type)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Split dataset in train/test sets\n",
    "pct_train = 0.8\n",
    "n_train_samples = int(len(y) * pct_train)\n",
    "\n",
    "y_train = y[:n_train_samples]\n",
    "y_val = y[n_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e0318-03cf-4f14-90df-4521d4e4a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassengerDataset(Dataset):\n",
    "    def __init__(self, X, timesteps):\n",
    "        self.X = X\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - timesteps - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        st = idx\n",
    "        ed = idx + self.timesteps\n",
    "\n",
    "        x = self.X[st:ed, np.newaxis]\n",
    "        y = self.X[[ed]]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aee48c-32ac-4d5e-ae8e-2163876904ed",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303dba62-b7f4-4336-926e-2c5a0e94e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, : -self.chomp_size]\n",
    "\n",
    "\n",
    "class SquezeeChannels(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquezeeChannels, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.squeeze(x, dim=-1)\n",
    "\n",
    "\n",
    "class CausalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, dilation, dropout=0.2):\n",
    "        super(CausalBlock, self).__init__()\n",
    "\n",
    "        # Initally pad both sizes but discard right padding\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            n_inputs, n_outputs, kernel_size, padding=padding, dilation=dilation\n",
    "        )\n",
    "        # Discard right padding elements to make conv causal\n",
    "        self.comp1d = Chomp1d(padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1d, self.comp1d, self.relu, self.dropout)\n",
    "\n",
    "        self.upperdownsample = (\n",
    "            torch.nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1d.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.upperdownsample is None:\n",
    "            res = x\n",
    "        else:\n",
    "            res = self.upperdownsample(x)\n",
    "\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class CausalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(CausalConvNet, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Number of layers determined by list of num_channels\n",
    "        num_layers = len(num_channels)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            # Dilation grows by 2x on each level\n",
    "            dilation_size = 2**i\n",
    "\n",
    "            # Initial inputs channels equals `num_inputs\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i - 1]\n",
    "            out_channels = num_channels[i]\n",
    "\n",
    "            layers += [\n",
    "                CausalBlock(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size,\n",
    "                    dilation=dilation_size,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7380157-fa7d-4c10-83f2-36feca0aafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TCN, self).__init__()\n",
    "\n",
    "        # Linear input size\n",
    "        out_channels = num_channels[-1]\n",
    "\n",
    "        # Network architecture\n",
    "        self.tcn = CausalConvNet(\n",
    "            input_size, num_channels, kernel_size=kernel_size, dropout=dropout\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.squeeze = SquezeeChannels()\n",
    "        self.linear = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "        self.network = torch.nn.Sequential(\n",
    "            self.tcn, self.dropout, self.squeeze, self.linear\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4243d47-fccb-4115-924e-d4fd1434a322",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852f29a-e9cb-4007-996f-a661147c833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch, dataloader, model, loss_fn, optimizer, history=None):\n",
    "    # Set train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss_batch = []\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(\n",
    "                f\"Epoch:{epoch} loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\", end=\"\\r\"\n",
    "            )\n",
    "            train_loss_batch.append(loss)\n",
    "\n",
    "    # End of epoch\n",
    "    print(f\"Epoch:{epoch} loss: {loss:>7f}  [{size:>5d}/{size:>5d}]\")\n",
    "\n",
    "    # Save loss\n",
    "    if isinstance(history, defaultdict):\n",
    "        train_loss = sum(train_loss_batch) / len(train_loss_batch)\n",
    "        history[\"loss\"].append(train_loss)\n",
    "\n",
    "\n",
    "def test_loop(epoch, dataloader, model, loss_fn, history=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "\n",
    "    # Set evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch:{epoch} Avg loss: {val_loss:>8f} \\n\")\n",
    "\n",
    "    if isinstance(history, defaultdict):\n",
    "        history[\"val_loss\"].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4cc8d2-1a7b-4747-8d05-d68260b7dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 5\n",
    "num_epochs = 50\n",
    "\n",
    "# Keep track of model metrics\n",
    "history = defaultdict(list)\n",
    "\n",
    "# Model hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Build DataLoader\n",
    "train_dataset = PassengerDataset(y_train, timesteps=timesteps)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = PassengerDataset(y_val, timesteps=timesteps)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = TCN(input_size=timesteps, num_channels=[12, 24], kernel_size=2).to(device)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Initalizer loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8173e5-6293-4d9e-a45e-0b57b3ac6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loop(epoch, train_dl, model, loss_fn, optimizer, history)\n",
    "    test_loop(epoch, train_dl, model, loss_fn, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f157914-d0d3-40ad-bb53-9c303f2c29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "_ = ax.plot(history[\"loss\"], label=\"loss\")\n",
    "_ = ax.plot(history[\"val_loss\"], label=\"val_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61411643-6683-4753-b5f4-c4189a9c7e55",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b6a5b-6925-40aa-9eb4-8c38f054378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for batch in val_dl:\n",
    "    y_pred_batch = model(batch[0])\n",
    "    y_true_batch = batch[1]\n",
    "\n",
    "    y_pred.extend(y_pred_batch[:, 0].detach().cpu().numpy())\n",
    "    y_true.extend(y_true_batch[:, 0].detach().cpu().numpy())\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87761b80-ac2f-4d18-912b-1a06d175dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((y_true - y_pred) ** 2)\n",
    "print(f\"MSE: {mse:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaae4f7-da51-4c37-8d26-82a59a5cb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((y_true[1:] - y_true[:-1]) ** 2)\n",
    "print(f\"MSE: {mse:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e00b03-872b-4d40-b10e-d611280f3c1b",
   "metadata": {},
   "source": [
    "Visualize prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afccf5-d57a-4c06-866b-0c3241fa719f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "_ = ax.plot(y_pred, label=\"pred\")\n",
    "_ = ax.plot(y_true, label=\"true\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
