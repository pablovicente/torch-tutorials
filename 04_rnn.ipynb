{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806f67f2-b775-4080-9c60-36814d917098",
   "metadata": {},
   "source": [
    "### RNN in PyTorch\n",
    "\n",
    "References:\n",
    "- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "- https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fff9c-2da9-4124-8a61-c0abbd670ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf94e03-9621-414f-879a-926bed210163",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d7df14-af54-4d88-b85c-67cb626450d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3e0ae-0074-42aa-9221-36f26a5d7f20",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15019c40-2148-4935-bafe-98339deb0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "x = np.arange(0, num_steps)\n",
    "y = np.sin(x / 20)\n",
    "\n",
    "# Cast to float 32\n",
    "x = x.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 2))\n",
    "_ = ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5bdb-2f04-487e-ba7e-7b8ef47ae2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinDataset(Dataset):\n",
    "    def __init__(self, X, timesteps):\n",
    "        self.X = X\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - timesteps - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        st = idx\n",
    "        ed = idx + self.timesteps\n",
    "\n",
    "        x = self.X[st:ed, np.newaxis]\n",
    "        y = self.X[[ed]]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdf61a-57b1-4971-a5a7-657f7961a6e9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9ecbc-d40b-4cbc-bdf3-69c384622bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, timesteps, num_ft, hidden_units):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_ft = num_ft\n",
    "        self.timesteps = timesteps\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "        self.rnn = nn.RNN(num_ft, hidden_units, 1)\n",
    "        self.linear = nn.Linear(hidden_units, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Inital hidden state\n",
    "        h0 = torch.randn(1, self.timesteps, self.hidden_units)\n",
    "\n",
    "        # Pass input through RNN\n",
    "        out, h_n = self.rnn(x, h0)\n",
    "\n",
    "        # Get last state\n",
    "        out = out[:, -1]\n",
    "\n",
    "        # Pass last state through linear layer\n",
    "        out = self.linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de6cd8-849d-4251-8c75-282d56d68fe1",
   "metadata": {},
   "source": [
    "Check model\n",
    "\n",
    "Building our module and running through one batch could help debugging the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a252bd-bffa-40b6-aacd-a9340ff80262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataLoader\n",
    "timesteps = 5\n",
    "\n",
    "sin_ds = SinDataset(y, timesteps=timesteps)\n",
    "train_dl = DataLoader(sin_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "print(batch[0].shape, batch[1].shape)\n",
    "\n",
    "model = RNN(timesteps, num_ft=1, hidden_units=12)\n",
    "_ = model(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414465ba-354c-4159-9e10-617c71d52f84",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d4b0a-d1f1-4dd3-aeb0-471386740d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch, dataloader, model, loss_fn, optimizer, history=None):\n",
    "    # Set train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss_batch = []\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        print(f\"Epoch:{epoch} loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\", end=\"\\r\")\n",
    "\n",
    "        train_loss_batch.append(loss)\n",
    "\n",
    "    # End of epoch\n",
    "    print(f\"Epoch:{epoch} loss: {loss:>7f}  [{size:>5d}/{size:>5d}]\")\n",
    "\n",
    "    # Save loss\n",
    "    if isinstance(history, defaultdict):\n",
    "        train_loss = sum(train_loss_batch) / len(train_loss_batch)\n",
    "        history[\"loss\"].append(train_loss)\n",
    "\n",
    "\n",
    "def test_loop(epoch, dataloader, model, loss_fn, history=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "\n",
    "    # Set evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    print(\n",
    "        f\"Epoch:{epoch} Avg loss: {val_loss:>8f} \\n\"\n",
    "    )\n",
    "\n",
    "    if isinstance(history, defaultdict):\n",
    "        history[\"val_loss\"].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ecb2f-d0b8-4791-b874-dbc41fa85f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 5\n",
    "num_epochs = 100\n",
    "\n",
    "# Keep track of model metrics\n",
    "history = defaultdict(list)\n",
    "\n",
    "# Model hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Build DataLoader\n",
    "train_dataset = SinDataset(y, timesteps=timesteps)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = RNN(timesteps, num_ft=1, hidden_units=12).to(device)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Initalizer loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6849f-39ff-4f1d-9cb4-345404f02559",
   "metadata": {},
   "source": [
    "For simplicity we are evaluating in the same dataset\n",
    "\n",
    "You should always evaluate model performance on a separate holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b16ebf-3b90-42ec-aa4e-95992dcedc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model for `num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    train_loop(epoch, train_dl, model, loss_fn, optimizer, history)\n",
    "    test_loop(epoch, train_dl, model, loss_fn, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491fa43f-b467-409f-b16a-690f71ad86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "_ = ax.plot(history[\"loss\"], label=\"loss\")\n",
    "_ = ax.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad85787-2b35-4f81-94f0-7bd4ddaac353",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55fe87-a3bd-41fd-8d55-a5329a402467",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for batch in train_dl:\n",
    "    y_pred_batch = model(batch[0])\n",
    "    y_true_batch = batch[1]\n",
    "\n",
    "    y_pred.extend(y_pred_batch[:, 0].detach().cpu().numpy())\n",
    "    y_true.extend(y_true_batch[:, 0].detach().cpu().numpy())\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb851d36-9b1c-4f9e-b6ad-775072913da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((y_true - y_pred) ** 2)\n",
    "print(f'MSE: {mse:.4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
